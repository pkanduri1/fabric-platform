# US008: Real-Time Job Monitoring Dashboard - REVISED Implementation Plan

## Document Control

| Field | Value |
|-------|-------|
| Document Title | US008: Real-Time Job Monitoring Dashboard - REVISED Implementation Plan |
| Version | 2.0 |
| Date | 2025-08-08 |
| Author | Senior Full Stack Developer |
| Review Status | **PENDING RE-REVIEW** |
| Classification | INTERNAL - BANKING CONFIDENTIAL |
| Previous Version | 1.0 (REVISION REQUIRED) |
| Architect Review Score | 87/100 (Previous) |

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|---------|
| 2025-08-08 | 1.0 | Initial implementation plan | Senior Full Stack Developer |
| 2025-08-08 | 2.0 | Revised plan addressing critical architecture review requirements | Senior Full Stack Developer |

---

## Executive Summary

### Revision Overview
This revised implementation plan addresses all CRITICAL requirements identified in the architecture review (Score: 87/100) and implements HIGH priority recommendations to ensure banking-grade security, compliance, and performance standards.

### Key Revisions Implemented

1. **Enhanced WebSocket Security Architecture** - Redis-based session clustering with token rotation
2. **Optimized Database Design** - Time-series partitioned tables replacing inefficient CLOB approach  
3. **Comprehensive SOX Compliance** - Audit logging and workflow-based change control
4. **Extended Timeline** - Increased from 5 weeks to 8 weeks for banking-grade implementation
5. **Performance Optimization** - Delta updates, circuit breakers, and adaptive intervals

### Implementation Readiness
**Status: READY FOR ARCHITECTURE RE-REVIEW**

All CRITICAL and HIGH priority requirements from the architecture review have been addressed in this revised plan.

---

## 1. ANALYSIS & REQUIREMENTS

### 1.1 Business Requirements
**User Story:** As an Operations Manager, I want a real-time dashboard to monitor all active batch jobs so that I can quickly identify issues and take corrective action to maintain SLA compliance.

**Acceptance Criteria:**
- Real-time visibility of all active batch jobs (refreshed every 5 seconds)
- Support for 50+ concurrent users with enterprise-grade security
- Mobile-responsive design for 24/7 operational support
- Integration with existing Epic 2-3 monitoring infrastructure
- SOX-compliant audit logging and workflow-based configuration management
- Sub-3-second dashboard load times with 99.9% availability

### 1.2 Technical Requirements - Enhanced

#### Security Requirements (Enhanced)
- **WebSocket Security**: Enterprise-grade session management with Redis clustering
- **Token Management**: JWT rotation every 15 minutes with validation
- **CSRF Protection**: WebSocket-specific CSRF tokens and origin validation
- **Rate Limiting**: Connection-level rate limiting with IP-based throttling
- **Session Validation**: Real-time session validation with automatic termination
- **Input Validation**: Comprehensive sanitization for all WebSocket messages

#### Performance Requirements (Enhanced)
- **Concurrent Users**: 50+ users with horizontal scaling capability
- **Update Frequency**: Adaptive 5-second intervals based on system load
- **Response Time**: <2 seconds dashboard load with Redis caching
- **Message Optimization**: Delta updates with JSON compression
- **Database Performance**: Time-series queries optimized with proper indexing

#### Compliance Requirements (Enhanced)
- **SOX Compliance**: Comprehensive audit trail for all dashboard interactions
- **Change Control**: Workflow-based approval for monitoring configuration changes
- **Data Integrity**: Tamper-evident logging with digital signatures
- **Access Control**: Role-based data filtering with segregation of duties

---

## 2. ENHANCED SECURITY ARCHITECTURE

### 2.1 WebSocket Security Framework

#### Enhanced Session Management
```java
@Component
@RequiredArgsConstructor
public class EnterpriseWebSocketHandler extends TextWebSocketHandler {
    
    private final RedisTemplate<String, Object> redisTemplate;
    private final JwtTokenProvider tokenProvider;
    private final AuditService auditService;
    private final RateLimitingService rateLimiter;
    
    @Override
    public void afterConnectionEstablished(WebSocketSession session) throws Exception {
        try {
            // Enhanced multi-layer security validation
            String token = extractTokenFromSession(session);
            String clientIp = getClientIP(session);
            
            // 1. Token validation with rotation check
            if (!tokenProvider.validateTokenWithRotation(token)) {
                log.warn("WebSocket connection rejected: invalid or expired token for session {}", session.getId());
                session.close(CloseStatus.NOT_ACCEPTABLE.withReason("Authentication failed"));
                auditService.logSecurityEvent("WEBSOCKET_AUTH_FAILURE", session, "TOKEN_INVALID");
                return;
            }
            
            // 2. Rate limiting validation
            if (!rateLimiter.tryAcquire(clientIp, "websocket_connection", 10, Duration.ofMinutes(1))) {
                log.warn("WebSocket connection rejected: rate limit exceeded for IP {}", clientIp);
                session.close(CloseStatus.POLICY_VIOLATION.withReason("Rate limit exceeded"));
                auditService.logSecurityEvent("WEBSOCKET_RATE_LIMIT", session, clientIp);
                return;
            }
            
            // 3. Redis-based distributed session management
            String sessionKey = "websocket:session:" + session.getId();
            String userId = getUserFromToken(token);
            
            Map<String, Object> sessionData = Map.of(
                "userId", userId,
                "connectedAt", Instant.now().toString(),
                "lastActivity", Instant.now().toString(),
                "clientIp", clientIp,
                "userAgent", session.getHandshakeHeaders().getFirst("User-Agent"),
                "roles", getUserRoles(token)
            );
            
            redisTemplate.opsForHash().putAll(sessionKey, sessionData);
            redisTemplate.expire(sessionKey, Duration.ofHours(1));
            
            // 4. Register in distributed session manager
            sessionManager.registerSession(session, userId, getUserRoles(token));
            
            // 5. Audit successful connection
            auditService.logSecurityEvent("WEBSOCKET_CONNECTED", session, userId);
            
            log.info("WebSocket connection established successfully for user: {}, session: {}", userId, session.getId());
            
        } catch (Exception e) {
            log.error("Error establishing WebSocket connection", e);
            session.close(CloseStatus.SERVER_ERROR.withReason("Connection failed"));
            auditService.logSecurityEvent("WEBSOCKET_CONNECTION_ERROR", session, e.getMessage());
        }
    }
    
    @Override
    public void afterConnectionClosed(WebSocketSession session, CloseStatus status) throws Exception {
        String sessionKey = "websocket:session:" + session.getId();
        
        // Clean up Redis session data
        redisTemplate.delete(sessionKey);
        
        // Unregister from session manager
        sessionManager.unregisterSession(session);
        
        // Audit connection closure
        auditService.logSecurityEvent("WEBSOCKET_DISCONNECTED", session, status.toString());
        
        log.info("WebSocket connection closed: session={}, status={}", session.getId(), status);
    }
    
    @Scheduled(fixedDelay = 60000) // Every minute
    public void validateActiveSessions() {
        sessionManager.getActiveSessions().forEach(session -> {
            try {
                String sessionKey = "websocket:session:" + session.getId();
                Map<Object, Object> sessionData = redisTemplate.opsForHash().entries(sessionKey);
                
                if (sessionData.isEmpty() || !tokenProvider.validateActiveSession(session)) {
                    log.warn("Terminating invalid session: {}", session.getId());
                    sessionManager.terminateSession(session);
                    auditService.logSecurityEvent("SESSION_TERMINATED", session, "VALIDATION_FAILED");
                }
            } catch (Exception e) {
                log.error("Error validating session: {}", session.getId(), e);
            }
        });
    }
}
```

#### WebSocket Security Configuration
```java
@Configuration
@EnableWebSocket
public class EnhancedWebSocketSecurityConfig implements WebSocketConfigurer {
    
    @Override
    public void registerWebSocketHandlers(WebSocketHandlerRegistry registry) {
        registry.addHandler(new EnterpriseWebSocketHandler(), "/ws/job-monitoring")
                .addInterceptors(new SecurityHandshakeInterceptor())
                .setAllowedOriginPatterns("https://*.truist.com", "https://fabric-*.truist.com")
                .withSockJS()
                .setSessionCookieNeeded(true)
                .setHeartbeatTime(25000)
                .setDisconnectDelay(5000)
                .setHttpMessageCacheSize(1000);
    }
    
    @Component
    @RequiredArgsConstructor
    public static class SecurityHandshakeInterceptor implements HandshakeInterceptor {
        
        private final CSRFTokenService csrfTokenService;
        private final RateLimitingService rateLimiter;
        
        @Override
        public boolean beforeHandshake(ServerHttpRequest request, 
                                     ServerHttpResponse response,
                                     WebSocketHandler wsHandler, 
                                     Map<String, Object> attributes) {
            
            try {
                // 1. Origin validation
                String origin = request.getHeaders().getOrigin();
                if (!validateOrigin(origin)) {
                    log.warn("WebSocket handshake rejected: invalid origin {}", origin);
                    response.setStatusCode(HttpStatus.FORBIDDEN);
                    return false;
                }
                
                // 2. CSRF token validation
                String csrfToken = request.getHeaders().getFirst("X-CSRF-Token");
                if (!csrfTokenService.validateToken(csrfToken)) {
                    log.warn("WebSocket handshake rejected: invalid CSRF token");
                    response.setStatusCode(HttpStatus.FORBIDDEN);
                    return false;
                }
                
                // 3. Rate limiting
                String clientIp = getClientIP(request);
                if (!rateLimiter.tryAcquire(clientIp, "websocket_handshake", 5, Duration.ofMinutes(1))) {
                    log.warn("WebSocket handshake rejected: rate limit exceeded for IP {}", clientIp);
                    response.setStatusCode(HttpStatus.TOO_MANY_REQUESTS);
                    return false;
                }
                
                // 4. Additional security headers
                response.getHeaders().add("X-Content-Type-Options", "nosniff");
                response.getHeaders().add("X-Frame-Options", "DENY");
                response.getHeaders().add("X-XSS-Protection", "1; mode=block");
                
                return true;
                
            } catch (Exception e) {
                log.error("Error during WebSocket handshake validation", e);
                response.setStatusCode(HttpStatus.INTERNAL_SERVER_ERROR);
                return false;
            }
        }
        
        private boolean validateOrigin(String origin) {
            if (origin == null) return false;
            
            List<String> allowedOrigins = Arrays.asList(
                "https://fabric-platform.truist.com",
                "https://fabric-platform-dev.truist.com",
                "https://fabric-platform-test.truist.com"
            );
            
            return allowedOrigins.stream().anyMatch(allowed -> 
                origin.matches(allowed.replace("*", ".*")));
        }
    }
}
```

### 2.2 Token Rotation and Validation

#### JWT Token Provider with Rotation
```java
@Service
@RequiredArgsConstructor
public class EnhancedJwtTokenProvider {
    
    private final RedisTemplate<String, Object> redisTemplate;
    
    @Value("${jwt.secret}")
    private String jwtSecret;
    
    @Value("${jwt.expiration:900000}") // 15 minutes
    private int jwtExpirationInMs;
    
    public boolean validateTokenWithRotation(String token) {
        try {
            Claims claims = extractClaims(token);
            String userId = claims.getSubject();
            Date expiration = claims.getExpiration();
            
            // Check if token is close to expiration (within 5 minutes)
            long timeUntilExpiration = expiration.getTime() - System.currentTimeMillis();
            if (timeUntilExpiration < 300000) { // 5 minutes
                // Initiate token rotation
                rotateTokenForUser(userId);
            }
            
            // Validate against Redis blacklist
            String tokenId = claims.get("jti", String.class);
            Boolean isBlacklisted = (Boolean) redisTemplate.opsForValue()
                    .get("blacklist:token:" + tokenId);
            
            return !Boolean.TRUE.equals(isBlacklisted) && 
                   !expiration.before(new Date());
                   
        } catch (Exception e) {
            log.warn("Token validation failed", e);
            return false;
        }
    }
    
    private void rotateTokenForUser(String userId) {
        // Generate new token
        String newToken = generateTokenForUser(userId);
        
        // Store new token in Redis with user mapping
        redisTemplate.opsForValue().set("user:token:" + userId, newToken, 
                Duration.ofMillis(jwtExpirationInMs));
        
        // Notify WebSocket sessions of token rotation
        sessionManager.notifyTokenRotation(userId, newToken);
    }
}
```

---

## 3. OPTIMIZED DATABASE ARCHITECTURE

### 3.1 Time-Series Database Design

#### Enhanced Database Schema
```sql
-- ENHANCED: Replace DASHBOARD_SNAPSHOTS with time-series approach
CREATE TABLE CM3INT.DASHBOARD_METRICS_TIMESERIES (
    metric_id NUMBER(19) PRIMARY KEY,
    metric_timestamp TIMESTAMP NOT NULL,
    execution_id VARCHAR2(100) NOT NULL,
    metric_type VARCHAR2(50) NOT NULL,
    metric_name VARCHAR2(100) NOT NULL,
    metric_value NUMBER(15,4),
    metric_unit VARCHAR2(20),
    metric_status VARCHAR2(20),
    source_system VARCHAR2(50),
    created_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    created_by VARCHAR2(100),
    correlation_id VARCHAR2(100),
    -- Compliance and audit fields
    audit_hash VARCHAR2(64), -- For tamper detection
    compliance_flags VARCHAR2(200)
) PARTITION BY RANGE (metric_timestamp) INTERVAL (NUMTODSINTERVAL(1, 'DAY'));

-- Time-series specific indexes for optimal query performance
CREATE INDEX idx_metrics_ts_realtime 
ON CM3INT.DASHBOARD_METRICS_TIMESERIES(metric_timestamp DESC, metric_type, execution_id)
LOCAL COMPRESS;

CREATE INDEX idx_metrics_execution_lookup 
ON CM3INT.DASHBOARD_METRICS_TIMESERIES(execution_id, metric_timestamp DESC, metric_type)
LOCAL COMPRESS;

-- Composite index for dashboard queries
CREATE INDEX idx_metrics_dashboard_query 
ON CM3INT.DASHBOARD_METRICS_TIMESERIES(metric_type, metric_status, metric_timestamp DESC)
LOCAL COMPRESS;

-- Enhanced BATCH_PROCESSING_STATUS for real-time monitoring
ALTER TABLE CM3INT.BATCH_PROCESSING_STATUS ADD (
    monitoring_enabled CHAR(1) DEFAULT 'Y' CHECK (monitoring_enabled IN ('Y', 'N')),
    dashboard_display_priority NUMBER(2) DEFAULT 5,
    alert_threshold_warning NUMBER(10,2),
    alert_threshold_critical NUMBER(10,2),
    real_time_metrics_enabled CHAR(1) DEFAULT 'Y',
    websocket_broadcast_enabled CHAR(1) DEFAULT 'Y',
    last_metrics_update TIMESTAMP,
    metrics_update_frequency NUMBER(10) DEFAULT 5000, -- milliseconds
    -- SOX compliance fields
    configuration_approved_by VARCHAR2(100),
    configuration_approved_date TIMESTAMP,
    configuration_change_id VARCHAR2(100)
);

-- Index for real-time monitoring queries
CREATE INDEX idx_batch_status_realtime_monitoring 
ON CM3INT.BATCH_PROCESSING_STATUS(
    monitoring_enabled,
    processing_status, 
    last_heartbeat DESC,
    execution_id,
    dashboard_display_priority
) COMPRESS;

-- WebSocket session tracking table
CREATE TABLE CM3INT.WEBSOCKET_SESSIONS (
    session_id VARCHAR2(100) PRIMARY KEY,
    user_id VARCHAR2(100) NOT NULL,
    connected_at TIMESTAMP NOT NULL,
    last_activity TIMESTAMP NOT NULL,
    client_ip VARCHAR2(50),
    user_agent VARCHAR2(500),
    session_status VARCHAR2(20) DEFAULT 'ACTIVE',
    roles CLOB, -- JSON array of user roles
    correlation_id VARCHAR2(100),
    created_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Audit table for WebSocket connections
CREATE TABLE CM3INT.WEBSOCKET_AUDIT_LOG (
    audit_id NUMBER(19) PRIMARY KEY,
    session_id VARCHAR2(100),
    event_type VARCHAR2(50) NOT NULL,
    event_description VARCHAR2(500),
    user_id VARCHAR2(100),
    client_ip VARCHAR2(50),
    event_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    event_data CLOB, -- JSON event details
    security_classification VARCHAR2(50),
    audit_hash VARCHAR2(64), -- Tamper detection
    correlation_id VARCHAR2(100)
);

-- Generate sequences
CREATE SEQUENCE CM3INT.METRICS_TIMESERIES_SEQ START WITH 1 INCREMENT BY 1 CACHE 1000;
CREATE SEQUENCE CM3INT.WEBSOCKET_AUDIT_SEQ START WITH 1 INCREMENT BY 1 CACHE 1000;

-- Automatic data retention policy
CREATE OR REPLACE PROCEDURE CM3INT.PURGE_DASHBOARD_METRICS_DATA AS
BEGIN
    -- Purge metrics data older than 90 days (configurable)
    DELETE FROM CM3INT.DASHBOARD_METRICS_TIMESERIES 
    WHERE metric_timestamp < SYSTIMESTAMP - INTERVAL '90' DAY;
    
    -- Purge WebSocket audit logs older than 7 years (SOX requirement)
    DELETE FROM CM3INT.WEBSOCKET_AUDIT_LOG 
    WHERE event_timestamp < SYSTIMESTAMP - INTERVAL '7' YEAR;
    
    COMMIT;
    
    -- Gather statistics for optimal query plans
    DBMS_STATS.GATHER_TABLE_STATS('CM3INT', 'DASHBOARD_METRICS_TIMESERIES');
    DBMS_STATS.GATHER_TABLE_STATS('CM3INT', 'BATCH_PROCESSING_STATUS');
END;
/

-- Schedule automatic purging
BEGIN
    DBMS_SCHEDULER.CREATE_JOB (
        job_name        => 'PURGE_DASHBOARD_METRICS_JOB',
        job_type        => 'PLSQL_BLOCK',
        job_action      => 'BEGIN CM3INT.PURGE_DASHBOARD_METRICS_DATA; END;',
        start_date      => SYSTIMESTAMP,
        repeat_interval => 'FREQ=DAILY; BYHOUR=2; BYMINUTE=0',
        enabled         => TRUE
    );
END;
/
```

### 3.2 Redis Caching Layer

#### Redis Configuration for Performance
```java
@Configuration
@EnableCaching
@RequiredArgsConstructor
public class RedisCacheConfig {
    
    @Bean
    public LettuceConnectionFactory redisConnectionFactory() {
        RedisStandaloneConfiguration config = new RedisStandaloneConfiguration();
        config.setHostName("${redis.host:localhost}");
        config.setPort("${redis.port:6379}");
        config.setPassword("${redis.password}");
        config.setDatabase("${redis.database:0}");
        
        LettuceClientConfiguration clientConfig = LettuceClientConfiguration.builder()
                .clientOptions(ClientOptions.builder()
                    .autoReconnect(true)
                    .pingBeforeActivateConnection(true)
                    .build())
                .commandTimeout(Duration.ofSeconds(2))
                .build();
                
        return new LettuceConnectionFactory(config, clientConfig);
    }
    
    @Bean
    public RedisTemplate<String, Object> redisTemplate() {
        RedisTemplate<String, Object> template = new RedisTemplate<>();
        template.setConnectionFactory(redisConnectionFactory());
        
        // Use JSON serialization for complex objects
        Jackson2JsonRedisSerializer<Object> serializer = 
            new Jackson2JsonRedisSerializer<>(Object.class);
        
        template.setDefaultSerializer(serializer);
        template.setKeySerializer(new StringRedisSerializer());
        template.setHashKeySerializer(new StringRedisSerializer());
        template.setValueSerializer(serializer);
        template.setHashValueSerializer(serializer);
        
        return template;
    }
    
    @Bean
    public CacheManager cacheManager() {
        RedisCacheManager.Builder builder = RedisCacheManager
            .RedisCacheManagerBuilder
            .fromConnectionFactory(redisConnectionFactory())
            .cacheDefaults(cacheConfiguration());
            
        return builder.build();
    }
    
    private RedisCacheConfiguration cacheConfiguration() {
        return RedisCacheConfiguration.defaultCacheConfig()
            .entryTtl(Duration.ofSeconds(30)) // Default 30-second TTL
            .serializeKeysWith(RedisSerializationContext.SerializationPair
                .fromSerializer(new StringRedisSerializer()))
            .serializeValuesWith(RedisSerializationContext.SerializationPair
                .fromSerializer(new Jackson2JsonRedisSerializer<>(Object.class)))
            .disableCachingNullValues();
    }
}
```

#### Dashboard Caching Service
```java
@Service
@RequiredArgsConstructor
public class DashboardCacheService {
    
    private final RedisTemplate<String, Object> redisTemplate;
    
    @Cacheable(value = "dashboard:metrics", key = "#executionId")
    public DashboardMetrics getCachedMetrics(String executionId) {
        return fetchMetricsFromDatabase(executionId);
    }
    
    @CacheEvict(value = "dashboard:metrics", key = "#executionId")
    public void evictMetricsCache(String executionId) {
        log.debug("Evicted dashboard metrics cache for execution: {}", executionId);
    }
    
    public void cacheJobUpdate(String executionId, JobUpdate update) {
        String key = "dashboard:job:update:" + executionId;
        redisTemplate.opsForValue().set(key, update, Duration.ofMinutes(5));
    }
    
    public Optional<JobUpdate> getCachedJobUpdate(String executionId) {
        String key = "dashboard:job:update:" + executionId;
        JobUpdate update = (JobUpdate) redisTemplate.opsForValue().get(key);
        return Optional.ofNullable(update);
    }
}
```

---

## 4. SOX COMPLIANCE IMPLEMENTATION

### 4.1 Comprehensive Audit Framework

#### Enhanced Audit Service
```java
@Service
@RequiredArgsConstructor
@Transactional
public class SOXComplianceAuditService {
    
    private final ExecutionAuditRepository auditRepository;
    private final WebSocketAuditRepository wsAuditRepository;
    private final RedisTemplate<String, Object> redisTemplate;
    private final MessageDigest messageDigest = MessageDigest.getInstance("SHA-256");
    
    public void logDashboardAccess(DashboardAccessEvent event) {
        ExecutionAuditEntity auditRecord = ExecutionAuditEntity.builder()
                .executionId("DASHBOARD_ACCESS_" + System.currentTimeMillis())
                .eventType(ExecutionAuditEntity.EventType.DASHBOARD_ACCESS)
                .eventDescription("User accessed monitoring dashboard")
                .userId(event.getUserId())
                .sourceIp(event.getSourceIp())
                .performanceData(buildAccessMetadata(event))
                .complianceFlags("SOX_AUDIT_REQUIRED,DASHBOARD_ACCESS")
                .correlationId(event.getCorrelationId())
                .auditHash(calculateAuditHash(event))
                .createdDate(Instant.now())
                .build();
        
        auditRepository.save(auditRecord);
        
        // Also log to Redis for real-time audit monitoring
        cacheAuditEvent(auditRecord);
    }
    
    public void logWebSocketEvent(String sessionId, String eventType, 
                                 String userId, String description) {
        WebSocketAuditLog auditLog = WebSocketAuditLog.builder()
                .sessionId(sessionId)
                .eventType(eventType)
                .eventDescription(description)
                .userId(userId)
                .clientIp(getCurrentClientIp())
                .eventTimestamp(Instant.now())
                .securityClassification("SOX_AUDIT_REQUIRED")
                .correlationId(MDC.get("correlationId"))
                .auditHash(calculateWebSocketAuditHash(sessionId, eventType, userId))
                .build();
        
        wsAuditRepository.save(auditLog);
    }
    
    public void logConfigurationChange(ConfigurationChangeEvent event) {
        ExecutionAuditEntity auditRecord = ExecutionAuditEntity.builder()
                .executionId("CONFIG_CHANGE_" + System.currentTimeMillis())
                .eventType(ExecutionAuditEntity.EventType.CONFIGURATION_CHANGE)
                .eventDescription("Monitoring configuration changed: " + event.getChangeDescription())
                .userId(event.getChangedBy())
                .sourceIp(event.getSourceIp())
                .performanceData(JsonUtils.toJson(event.getChangeDetails()))
                .complianceFlags("SOX_AUDIT_REQUIRED,CONFIG_CHANGE,REQUIRES_APPROVAL")
                .correlationId(event.getCorrelationId())
                .auditHash(calculateAuditHash(event))
                .createdDate(Instant.now())
                .build();
        
        auditRepository.save(auditRecord);
        
        // Trigger workflow approval if required
        if (event.requiresApproval()) {
            workflowService.initiateApprovalProcess(event);
        }
    }
    
    private String calculateAuditHash(Object event) {
        try {
            String eventJson = JsonUtils.toJson(event);
            byte[] hash = messageDigest.digest(eventJson.getBytes(StandardCharsets.UTF_8));
            return Base64.getEncoder().encodeToString(hash);
        } catch (Exception e) {
            log.error("Error calculating audit hash", e);
            return "HASH_CALCULATION_FAILED";
        }
    }
    
    @Scheduled(fixedDelay = 300000) // Every 5 minutes
    public void validateAuditIntegrity() {
        // Verify audit log integrity by recalculating hashes
        List<ExecutionAuditEntity> recentAudits = auditRepository
                .findByCreatedDateAfter(Instant.now().minus(1, ChronoUnit.HOURS));
        
        for (ExecutionAuditEntity audit : recentAudits) {
            String calculatedHash = recalculateHash(audit);
            if (!Objects.equals(audit.getAuditHash(), calculatedHash)) {
                log.error("AUDIT INTEGRITY VIOLATION: Audit record {} has been tampered with", 
                         audit.getId());
                alertService.sendCriticalAlert("AUDIT_INTEGRITY_VIOLATION", audit);
            }
        }
    }
}
```

### 4.2 Workflow-Based Configuration Management

#### Configuration Change Workflow
```java
@Service
@RequiredArgsConstructor
public class MonitoringConfigurationWorkflowService {
    
    private final ConfigurationApprovalRepository approvalRepository;
    private final SOXComplianceAuditService auditService;
    private final NotificationService notificationService;
    
    @Transactional
    public ConfigurationChangeRequest initiateConfigurationChange(
            ConfigurationChangeRequest request) {
        
        // Validate segregation of duties
        if (!validateSegregationOfDuties(request)) {
            throw new SecurityException("Segregation of duties violation: " +
                "User cannot approve their own configuration changes");
        }
        
        // Create approval workflow
        ConfigurationApprovalEntity approval = ConfigurationApprovalEntity.builder()
                .changeRequestId(UUID.randomUUID().toString())
                .requestedBy(request.getRequestedBy())
                .changeType(request.getChangeType())
                .changeDescription(request.getChangeDescription())
                .configurationData(JsonUtils.toJson(request.getConfigurationChanges()))
                .approvalStatus(ApprovalStatus.PENDING)
                .requestedDate(Instant.now())
                .businessJustification(request.getBusinessJustification())
                .riskAssessment(request.getRiskAssessment())
                .build();
        
        approval = approvalRepository.save(approval);
        
        // Audit the workflow initiation
        auditService.logConfigurationChange(ConfigurationChangeEvent.builder()
                .changeRequestId(approval.getChangeRequestId())
                .eventType("WORKFLOW_INITIATED")
                .changedBy(request.getRequestedBy())
                .changeDescription(request.getChangeDescription())
                .requiresApproval(true)
                .build());
        
        // Notify approvers
        notificationService.notifyConfigurationApprovers(approval);
        
        return approval.toChangeRequest();
    }
    
    @Transactional
    public void approveConfigurationChange(String changeRequestId, 
                                          String approvedBy, 
                                          String approvalComments) {
        
        ConfigurationApprovalEntity approval = approvalRepository
                .findByChangeRequestId(changeRequestId)
                .orElseThrow(() -> new EntityNotFoundException("Configuration change request not found"));
        
        // Validate approver authority
        if (!validateApproverAuthority(approvedBy, approval.getChangeType())) {
            throw new SecurityException("User does not have authority to approve this change type");
        }
        
        // Apply configuration changes
        applyConfigurationChanges(approval);
        
        // Update approval status
        approval.setApprovalStatus(ApprovalStatus.APPROVED);
        approval.setApprovedBy(approvedBy);
        approval.setApprovedDate(Instant.now());
        approval.setApprovalComments(approvalComments);
        
        approvalRepository.save(approval);
        
        // Audit the approval
        auditService.logConfigurationChange(ConfigurationChangeEvent.builder()
                .changeRequestId(changeRequestId)
                .eventType("CONFIGURATION_APPROVED_AND_APPLIED")
                .changedBy(approvedBy)
                .changeDescription("Configuration change approved and applied")
                .requiresApproval(false)
                .build());
        
        log.info("Configuration change {} approved and applied by {}", 
                changeRequestId, approvedBy);
    }
    
    private boolean validateSegregationOfDuties(ConfigurationChangeRequest request) {
        // Ensure the requester cannot be their own approver
        // Additional business rules for segregation of duties
        return !request.getRequestedBy().equals(request.getProposedApprover()) &&
               hasRequiredSeparationLevel(request.getRequestedBy(), request.getChangeType());
    }
}
```

---

## 5. PERFORMANCE OPTIMIZATION FRAMEWORK

### 5.1 Delta Update System

#### Optimized WebSocket Broadcasting
```java
@Service
@RequiredArgsConstructor
public class OptimizedJobMonitoringService {
    
    private final RedisTemplate<String, Object> redisTemplate;
    private final SessionManager sessionManager;
    private final CircuitBreakerFactory circuitBreakerFactory;
    
    @Scheduled(fixedDelayString = "${monitoring.update.interval:5000}")
    public void broadcastJobUpdates() {
        CircuitBreaker circuitBreaker = circuitBreakerFactory.create("job-monitoring-updates");
        
        try {
            circuitBreaker.run(() -> {
                // Get current state
                JobMonitoringState currentState = getCurrentJobState();
                
                // Calculate deltas from previous state
                JobMonitoringDelta delta = calculateDelta(currentState);
                
                if (delta.hasChanges()) {
                    // Compress delta for efficient transmission
                    CompressedJobUpdate compressedUpdate = compressUpdate(delta);
                    
                    // Broadcast delta to active sessions with role-based filtering
                    broadcastDeltaToSessions(compressedUpdate);
                    
                    // Update cached state
                    cacheCurrentState(currentState);
                    
                    // Store metrics for adaptive interval calculation
                    updateBroadcastMetrics(compressedUpdate.getSize(), delta.getChangeCount());
                }
                
                return null;
            });
        } catch (Exception e) {
            log.error("Circuit breaker opened for job monitoring updates", e);
            // Fallback to basic status broadcast
            broadcastBasicStatus();
        }
    }
    
    private JobMonitoringDelta calculateDelta(JobMonitoringState currentState) {
        JobMonitoringState previousState = getCachedState();
        
        return JobMonitoringDelta.builder()
                .timestamp(Instant.now())
                .newJobs(findNewJobs(currentState, previousState))
                .updatedJobs(findUpdatedJobs(currentState, previousState))
                .completedJobs(findCompletedJobs(currentState, previousState))
                .metricsChanges(calculateMetricsChanges(currentState, previousState))
                .alertChanges(calculateAlertChanges(currentState, previousState))
                .build();
    }
    
    private void broadcastDeltaToSessions(CompressedJobUpdate update) {
        sessionManager.getActiveSessionsByRole().forEach((role, sessions) -> {
            // Filter update data based on user role
            CompressedJobUpdate roleFilteredUpdate = filterUpdateForRole(update, role);
            
            if (roleFilteredUpdate.hasData()) {
                sessions.parallelStream().forEach(session -> {
                    try {
                        sendUpdateToSession(session, roleFilteredUpdate);
                    } catch (Exception e) {
                        log.warn("Failed to send update to session {}", session.getId(), e);
                        sessionManager.handleSessionError(session, e);
                    }
                });
            }
        });
    }
    
    @Scheduled(fixedDelay = 60000) // Every minute
    public void adjustUpdateInterval() {
        BroadcastMetrics metrics = getBroadcastMetrics();
        
        int currentInterval = getCurrentUpdateInterval();
        int adjustedInterval = calculateAdaptiveInterval(metrics);
        
        if (adjustedInterval != currentInterval) {
            log.info("Adjusting broadcast interval from {}ms to {}ms based on system load", 
                    currentInterval, adjustedInterval);
            updateBroadcastInterval(adjustedInterval);
        }
    }
    
    private int calculateAdaptiveInterval(BroadcastMetrics metrics) {
        // Base interval of 5 seconds
        int baseInterval = 5000;
        
        // Increase interval if system is under high load
        if (metrics.getAverageProcessingTime() > 1000) { // 1 second
            return Math.min(baseInterval * 2, 15000); // Max 15 seconds
        }
        
        // Decrease interval if system has low load and high change frequency
        if (metrics.getAverageProcessingTime() < 200 && metrics.getChangeFrequency() > 0.5) {
            return Math.max(baseInterval / 2, 2000); // Min 2 seconds
        }
        
        return baseInterval;
    }
}
```

### 5.2 Circuit Breaker Implementation

#### Database Connection Circuit Breaker
```java
@Configuration
public class CircuitBreakerConfig {
    
    @Bean
    public CircuitBreakerFactory circuitBreakerFactory() {
        return CircuitBreakerFactory.builder("monitoring")
                .circuitBreakerConfigurer(id -> CircuitBreakerConfigBuilder.create(id)
                    .failureRateThreshold(50) // 50% failure rate
                    .waitDurationInOpenState(Duration.ofSeconds(30))
                    .slidingWindowSize(10)
                    .minimumNumberOfCalls(5)
                    .permittedNumberOfCallsInHalfOpenState(3)
                    .build())
                .timeLimiterConfigurer(id -> TimeLimiterConfigBuilder.create(id)
                    .timeoutDuration(Duration.ofSeconds(5))
                    .build())
                .build();
    }
}

@Service
@RequiredArgsConstructor
public class ResilientDashboardService {
    
    private final CircuitBreakerFactory circuitBreakerFactory;
    private final JobRepository jobRepository;
    private final DashboardCacheService cacheService;
    
    public DashboardData getDashboardData(String userId) {
        CircuitBreaker circuitBreaker = circuitBreakerFactory.create("dashboard-db");
        
        return circuitBreaker.run(
            // Primary operation
            () -> fetchFreshDashboardData(userId),
            
            // Fallback operation
            (exception) -> {
                log.warn("Circuit breaker fallback activated for dashboard data", exception);
                return getCachedDashboardData(userId)
                        .orElse(getMinimalDashboardData(userId));
            }
        );
    }
    
    private DashboardData fetchFreshDashboardData(String userId) {
        // This method can throw exceptions that will trip the circuit breaker
        return DashboardData.builder()
                .activeJobs(jobRepository.findActiveJobsForUser(userId))
                .systemMetrics(metricsService.getCurrentSystemMetrics())
                .alerts(alertService.getActiveAlerts(userId))
                .timestamp(Instant.now())
                .dataSource("DATABASE")
                .build();
    }
}
```

---

## 6. FRONTEND SECURITY & OPTIMIZATION

### 6.1 Enhanced React WebSocket Hook

#### Secure WebSocket Connection Management
```typescript
interface WebSocketConfig {
  url: string;
  protocols?: string[];
  maxReconnectAttempts?: number;
  reconnectInterval?: number;
  heartbeatInterval?: number;
}

export const useSecureJobMonitoringWebSocket = (config: WebSocketConfig) => {
  const [connectionState, setConnectionState] = useState<'connecting' | 'connected' | 'disconnected' | 'error'>('disconnected');
  const [data, setData] = useState<JobMonitoringUpdate | null>(null);
  const [error, setError] = useState<string | null>(null);
  
  const reconnectAttempts = useRef(0);
  const maxReconnectAttempts = config.maxReconnectAttempts || 5;
  const reconnectInterval = config.reconnectInterval || 5000;
  
  const connectWebSocket = useCallback(async () => {
    try {
      setConnectionState('connecting');
      setError(null);
      
      // Get CSRF token for WebSocket upgrade
      const csrfToken = await getCSRFToken();
      
      // Validate authentication token
      const authToken = getAuthToken();
      if (!authToken || isTokenExpired(authToken)) {
        throw new Error('Authentication required');
      }
      
      const wsUrl = new URL(config.url, window.location.origin);
      wsUrl.protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
      
      const ws = new WebSocket(wsUrl.toString(), config.protocols);
      
      // Set custom headers for security
      ws.addEventListener('open', (event) => {
        // Send authentication after connection opens
        ws.send(JSON.stringify({
          type: 'authenticate',
          token: authToken,
          csrfToken: csrfToken,
          timestamp: Date.now()
        }));
        
        setConnectionState('connected');
        reconnectAttempts.current = 0;
        
        // Start heartbeat
        startHeartbeat(ws);
      });
      
      ws.addEventListener('message', (event) => {
        try {
          const message = JSON.parse(event.data);
          
          // Validate message structure and source
          if (validateMessage(message)) {
            if (message.type === 'jobUpdate') {
              setData(message.data);
            } else if (message.type === 'tokenRotation') {
              // Handle token rotation
              updateAuthToken(message.newToken);
            }
          }
        } catch (err) {
          console.error('Error parsing WebSocket message:', err);
          setError('Invalid message received');
        }
      });
      
      ws.addEventListener('close', (event) => {
        setConnectionState('disconnected');
        
        if (reconnectAttempts.current < maxReconnectAttempts) {
          const delay = calculateBackoffDelay(reconnectAttempts.current);
          setTimeout(() => {
            reconnectAttempts.current++;
            connectWebSocket();
          }, delay);
        } else {
          setError('Maximum reconnection attempts exceeded');
        }
      });
      
      ws.addEventListener('error', (event) => {
        setConnectionState('error');
        setError('WebSocket connection error');
      });
      
      return () => {
        ws.close();
      };
      
    } catch (err) {
      setConnectionState('error');
      setError(err instanceof Error ? err.message : 'Connection failed');
    }
  }, [config.url, config.protocols]);
  
  const calculateBackoffDelay = (attempt: number): number => {
    // Exponential backoff with jitter
    const baseDelay = reconnectInterval;
    const exponentialDelay = baseDelay * Math.pow(2, attempt);
    const jitter = Math.random() * 1000; // Up to 1 second jitter
    
    return Math.min(exponentialDelay + jitter, 30000); // Max 30 seconds
  };
  
  const validateMessage = (message: any): boolean => {
    // Implement message validation logic
    return message && 
           typeof message.type === 'string' && 
           message.timestamp &&
           Date.now() - message.timestamp < 60000; // Message not older than 1 minute
  };
  
  useEffect(() => {
    const cleanup = connectWebSocket();
    return cleanup;
  }, [connectWebSocket]);
  
  return {
    connectionState,
    data,
    error,
    reconnect: connectWebSocket
  };
};
```

### 6.2 Role-Based Component Rendering

#### Secure Dashboard Component
```typescript
interface DashboardProps {
  userRoles: string[];
  userId: string;
}

const JobMonitoringDashboard: React.FC<DashboardProps> = ({ userRoles, userId }) => {
  const { connectionState, data, error, reconnect } = useSecureJobMonitoringWebSocket({
    url: '/ws/job-monitoring',
    maxReconnectAttempts: 5,
    reconnectInterval: 5000
  });
  
  const [filteredData, setFilteredData] = useState<JobMonitoringUpdate | null>(null);
  
  // Filter data based on user roles
  useEffect(() => {
    if (data) {
      const filtered = filterDataForRoles(data, userRoles);
      setFilteredData(filtered);
    }
  }, [data, userRoles]);
  
  const filterDataForRoles = (data: JobMonitoringUpdate, roles: string[]): JobMonitoringUpdate => {
    const hasOperationsRole = roles.includes('OPERATIONS_MANAGER');
    const hasViewerRole = roles.includes('OPERATIONS_VIEWER');
    
    return {
      ...data,
      jobs: data.jobs.filter(job => {
        if (hasOperationsRole) return true;
        if (hasViewerRole) return !job.containsSensitiveData;
        return false;
      }),
      metrics: hasOperationsRole ? data.metrics : sanitizeMetrics(data.metrics),
      alerts: filterAlertsForRoles(data.alerts, roles)
    };
  };
  
  const sanitizeMetrics = (metrics: SystemMetrics): SystemMetrics => {
    // Remove sensitive performance data for non-operations users
    return {
      ...metrics,
      databaseConnections: undefined,
      memoryUsage: metrics.memoryUsage > 80 ? 'HIGH' : 'NORMAL',
      errorRates: undefined
    };
  };
  
  if (connectionState === 'error' || error) {
    return (
      <ErrorBoundary>
        <div className="dashboard-error">
          <h3>Connection Error</h3>
          <p>{error}</p>
          <button onClick={reconnect}>Reconnect</button>
        </div>
      </ErrorBoundary>
    );
  }
  
  return (
    <div className="job-monitoring-dashboard">
      <DashboardHeader 
        connectionState={connectionState}
        userRoles={userRoles}
        userId={userId}
      />
      
      {filteredData && (
        <>
          <JobGrid 
            jobs={filteredData.jobs} 
            userRoles={userRoles}
          />
          <MetricsPanel 
            metrics={filteredData.metrics} 
            showSensitive={userRoles.includes('OPERATIONS_MANAGER')}
          />
          <AlertsPanel 
            alerts={filteredData.alerts}
            userRoles={userRoles}
          />
        </>
      )}
    </div>
  );
};
```

---

## 7. TESTING STRATEGY - ENHANCED

### 7.1 Security Testing Framework

#### WebSocket Security Tests
```java
@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT)
@TestPropertySource(locations = "classpath:application-test.properties")
class WebSocketSecurityTest {
    
    @Autowired
    private TestRestTemplate restTemplate;
    
    @Test
    void shouldRejectConnectionWithInvalidOrigin() throws Exception {
        URI uri = URI.create("ws://localhost:" + port + "/ws/job-monitoring");
        WebSocketStompClient client = new WebSocketStompClient(new StandardWebSocketClient());
        
        StompHeaders headers = new StompHeaders();
        headers.setOrigin("https://malicious-site.com");
        
        assertThrows(ConnectionException.class, () -> {
            client.connect(uri.toString(), headers, new StompSessionHandlerAdapter()).get();
        });
    }
    
    @Test
    void shouldRejectConnectionWithoutCSRFToken() throws Exception {
        URI uri = URI.create("ws://localhost:" + port + "/ws/job-monitoring");
        WebSocketStompClient client = new WebSocketStompClient(new StandardWebSocketClient());
        
        StompHeaders headers = new StompHeaders();
        headers.setOrigin("https://fabric-platform.truist.com");
        // No CSRF token provided
        
        assertThrows(ConnectionException.class, () -> {
            client.connect(uri.toString(), headers, new StompSessionHandlerAdapter()).get();
        });
    }
    
    @Test
    void shouldRotateTokenWhenNearExpiration() throws Exception {
        // Create token that expires in 4 minutes
        String nearExpiryToken = createTokenWithExpiry(Duration.ofMinutes(4));
        
        WebSocketSession session = establishConnectionWithToken(nearExpiryToken);
        
        // Wait for token rotation check
        Thread.sleep(6000);
        
        // Verify new token was issued
        verify(jwtTokenProvider).rotateTokenForUser(any());
        verify(sessionManager).notifyTokenRotation(any(), any());
    }
    
    @Test
    void shouldDetectAndTerminateHijackedSessions() throws Exception {
        WebSocketSession validSession = establishValidConnection();
        
        // Simulate session hijacking by invalidating the token
        invalidateTokenInRedis(validSession.getId());
        
        // Wait for session validation cycle
        Thread.sleep(65000);
        
        // Verify session was terminated
        assertThat(validSession.isOpen()).isFalse();
        verify(auditService).logSecurityEvent(eq("SESSION_TERMINATED"), any(), any());
    }
}
```

### 7.2 Performance Testing Framework

#### Load Testing Configuration
```java
@SpringBootTest
@ActiveProfiles("performance-test")
class WebSocketPerformanceTest {
    
    @Test
    void shouldHandleConcurrentConnections() throws Exception {
        int concurrentUsers = 60; // 20% above target
        CountDownLatch connectionsLatch = new CountDownLatch(concurrentUsers);
        List<WebSocketSession> sessions = new ArrayList<>();
        
        ExecutorService executor = Executors.newFixedThreadPool(20);
        
        for (int i = 0; i < concurrentUsers; i++) {
            executor.submit(() -> {
                try {
                    WebSocketSession session = establishValidConnection();
                    sessions.add(session);
                    connectionsLatch.countDown();
                } catch (Exception e) {
                    fail("Failed to establish connection: " + e.getMessage());
                }
            });
        }
        
        boolean allConnected = connectionsLatch.await(30, TimeUnit.SECONDS);
        assertThat(allConnected).isTrue();
        assertThat(sessions).hasSize(concurrentUsers);
        
        // Test broadcast performance
        long startTime = System.currentTimeMillis();
        broadcastTestMessage();
        long broadcastTime = System.currentTimeMillis() - startTime;
        
        assertThat(broadcastTime).isLessThan(2000); // Should complete within 2 seconds
        
        // Cleanup
        sessions.forEach(session -> {
            try { session.close(); } catch (Exception ignored) {}
        });
    }
    
    @Test
    void shouldMaintainPerformanceUnderHighMessageVolume() throws Exception {
        WebSocketSession session = establishValidConnection();
        
        // Send 1000 messages in 10 seconds
        int messageCount = 1000;
        long testDuration = 10000; // 10 seconds
        
        AtomicInteger messagesReceived = new AtomicInteger(0);
        AtomicLong totalResponseTime = new AtomicLong(0);
        
        for (int i = 0; i < messageCount; i++) {
            long sentTime = System.currentTimeMillis();
            sendTestMessage(session, "test_message_" + i);
            
            Thread.sleep(testDuration / messageCount);
        }
        
        Thread.sleep(5000); // Wait for all responses
        
        double averageResponseTime = totalResponseTime.get() / (double) messagesReceived.get();
        assertThat(averageResponseTime).isLessThan(200); // Average < 200ms
        assertThat(messagesReceived.get()).isGreaterThan(messageCount * 0.95); // 95% message success rate
    }
}
```

### 7.3 Compliance Testing Framework

#### SOX Compliance Tests
```java
@SpringBootTest
@TestPropertySource(locations = "classpath:application-compliance-test.properties")
class SOXComplianceTest {
    
    @Test
    void shouldAuditAllDashboardAccess() {
        // Simulate dashboard access
        DashboardAccessEvent accessEvent = DashboardAccessEvent.builder()
                .userId("test.user")
                .sourceIp("192.168.1.100")
                .accessType("DASHBOARD_VIEW")
                .correlationId(UUID.randomUUID().toString())
                .build();
        
        auditService.logDashboardAccess(accessEvent);
        
        // Verify audit record was created
        List<ExecutionAuditEntity> auditRecords = auditRepository
                .findByUserIdAndEventType("test.user", ExecutionAuditEntity.EventType.DASHBOARD_ACCESS);
        
        assertThat(auditRecords).hasSize(1);
        assertThat(auditRecords.get(0).getComplianceFlags()).contains("SOX_AUDIT_REQUIRED");
        assertThat(auditRecords.get(0).getAuditHash()).isNotNull();
    }
    
    @Test
    void shouldRequireApprovalForConfigurationChanges() {
        ConfigurationChangeRequest changeRequest = ConfigurationChangeRequest.builder()
                .changeType("ALERT_THRESHOLD")
                .changeDescription("Update critical alert threshold")
                .requestedBy("operations.user")
                .businessJustification("Reduce false positives")
                .configurationChanges(Map.of("threshold", "90"))
                .build();
        
        // Attempt to apply configuration change
        ConfigurationChangeRequest result = workflowService.initiateConfigurationChange(changeRequest);
        
        // Verify workflow was created and is pending approval
        assertThat(result.getApprovalStatus()).isEqualTo(ApprovalStatus.PENDING);
        
        ConfigurationApprovalEntity approval = approvalRepository
                .findByChangeRequestId(result.getChangeRequestId()).orElseThrow();
        
        assertThat(approval.getApprovalStatus()).isEqualTo(ApprovalStatus.PENDING);
        assertThat(approval.getRequestedBy()).isEqualTo("operations.user");
    }
    
    @Test
    void shouldValidateSegregationOfDuties() {
        ConfigurationChangeRequest changeRequest = ConfigurationChangeRequest.builder()
                .changeType("ALERT_THRESHOLD")
                .requestedBy("operations.manager")
                .proposedApprover("operations.manager") // Same user as requester
                .build();
        
        assertThrows(SecurityException.class, () -> {
            workflowService.initiateConfigurationChange(changeRequest);
        });
    }
}
```

---

## 8. DEPLOYMENT & INFRASTRUCTURE

### 8.1 Kubernetes Configuration

#### Enhanced Kubernetes Deployment
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: job-monitoring-dashboard
  namespace: fabric-platform
  labels:
    app: job-monitoring-dashboard
    version: v2.0
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1
  selector:
    matchLabels:
      app: job-monitoring-dashboard
  template:
    metadata:
      labels:
        app: job-monitoring-dashboard
        version: v2.0
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8080"
        prometheus.io/path: "/actuator/prometheus"
    spec:
      serviceAccountName: job-monitoring-service-account
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        fsGroup: 2000
      containers:
      - name: job-monitoring-dashboard
        image: truist/job-monitoring-dashboard:2.0
        imagePullPolicy: Always
        ports:
        - containerPort: 8080
          name: http
          protocol: TCP
        - containerPort: 8081
          name: management
          protocol: TCP
        env:
        - name: SPRING_PROFILES_ACTIVE
          value: "production,kubernetes"
        - name: REDIS_HOST
          value: "redis-cluster.fabric-platform.svc.cluster.local"
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: database-credentials
              key: url
        - name: JWT_SECRET
          valueFrom:
            secretKeyRef:
              name: jwt-secret
              key: secret
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /actuator/health/liveness
            port: 8081
          initialDelaySeconds: 60
          periodSeconds: 30
          timeoutSeconds: 10
        readinessProbe:
          httpGet:
            path: /actuator/health/readiness
            port: 8081
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
        securityContext:
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: true
          capabilities:
            drop:
            - ALL
        volumeMounts:
        - name: tmp
          mountPath: /tmp
        - name: logs
          mountPath: /app/logs
      volumes:
      - name: tmp
        emptyDir: {}
      - name: logs
        emptyDir: {}
      
---
apiVersion: v1
kind: Service
metadata:
  name: job-monitoring-dashboard-service
  namespace: fabric-platform
spec:
  selector:
    app: job-monitoring-dashboard
  ports:
  - name: http
    port: 80
    targetPort: 8080
  - name: management
    port: 8081
    targetPort: 8081
  type: ClusterIP

---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: job-monitoring-dashboard-ingress
  namespace: fabric-platform
  annotations:
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
    nginx.ingress.kubernetes.io/backend-protocol: "HTTP"
    nginx.ingress.kubernetes.io/websocket-services: "job-monitoring-dashboard-service"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "3600"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "3600"
spec:
  tls:
  - hosts:
    - fabric-platform.truist.com
    secretName: truist-tls-secret
  rules:
  - host: fabric-platform.truist.com
    http:
      paths:
      - path: /monitoring
        pathType: Prefix
        backend:
          service:
            name: job-monitoring-dashboard-service
            port:
              number: 80
```

### 8.2 Redis Cluster Configuration

#### Redis Deployment for Session Management
```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: redis-cluster
  namespace: fabric-platform
spec:
  serviceName: redis-cluster-headless
  replicas: 6
  selector:
    matchLabels:
      app: redis-cluster
  template:
    metadata:
      labels:
        app: redis-cluster
    spec:
      containers:
      - name: redis
        image: redis:7-alpine
        ports:
        - containerPort: 6379
          name: redis
        - containerPort: 16379
          name: cluster
        command:
        - redis-server
        - /etc/redis/redis.conf
        - --cluster-enabled yes
        - --cluster-config-file nodes.conf
        - --cluster-node-timeout 5000
        - --appendonly yes
        - --protected-mode no
        - --port 6379
        - --cluster-announce-port 6379
        - --cluster-announce-bus-port 16379
        volumeMounts:
        - name: redis-data
          mountPath: /data
        - name: redis-config
          mountPath: /etc/redis
        resources:
          requests:
            memory: "256Mi"
            cpu: "100m"
          limits:
            memory: "512Mi"
            cpu: "200m"
      volumes:
      - name: redis-config
        configMap:
          name: redis-config
  volumeClaimTemplates:
  - metadata:
      name: redis-data
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 10Gi
```

---

## 9. MONITORING & OBSERVABILITY - ENHANCED

### 9.1 Comprehensive Metrics Collection

#### Custom Micrometer Metrics
```java
@Component
@RequiredArgsConstructor
public class DashboardMetricsCollector {
    
    private final MeterRegistry meterRegistry;
    private final Counter webSocketConnectionsTotal;
    private final Timer messageBroadcastTimer;
    private final Gauge activeSessionsGauge;
    private final Counter securityViolationsTotal;
    
    @PostConstruct
    void initializeMetrics() {
        webSocketConnectionsTotal = Counter.builder("websocket.connections.total")
                .description("Total WebSocket connections established")
                .tag("component", "job-monitoring")
                .register(meterRegistry);
        
        messageBroadcastTimer = Timer.builder("websocket.message.broadcast.duration")
                .description("Time taken to broadcast messages to all sessions")
                .tag("component", "job-monitoring")
                .register(meterRegistry);
        
        activeSessionsGauge = Gauge.builder("websocket.sessions.active")
                .description("Number of active WebSocket sessions")
                .tag("component", "job-monitoring")
                .register(meterRegistry, this, DashboardMetricsCollector::getActiveSessionCount);
        
        securityViolationsTotal = Counter.builder("security.violations.total")
                .description("Total security violations detected")
                .tag("component", "job-monitoring")
                .register(meterRegistry);
    }
    
    public void recordWebSocketConnection(String userId, String userRole) {
        webSocketConnectionsTotal.increment(
            Tags.of(
                "user_role", userRole,
                "success", "true"
            )
        );
    }
    
    public void recordSecurityViolation(String violationType, String userId) {
        securityViolationsTotal.increment(
            Tags.of(
                "violation_type", violationType,
                "user_id", sanitizeUserId(userId)
            )
        );
    }
    
    public Timer.Sample startBroadcastTimer() {
        return Timer.start(meterRegistry);
    }
    
    public void recordBroadcastTime(Timer.Sample sample, int sessionCount, int messageSize) {
        sample.stop(messageBroadcastTimer.withTags(
            "session_count", String.valueOf(sessionCount),
            "message_size_kb", String.valueOf(messageSize / 1024)
        ));
    }
    
    private double getActiveSessionCount() {
        return sessionManager.getActiveSessionCount();
    }
}
```

### 9.2 Health Checks and Probes

#### Custom Health Indicators
```java
@Component
public class JobMonitoringHealthIndicator implements HealthIndicator {
    
    private final SessionManager sessionManager;
    private final RedisTemplate<String, Object> redisTemplate;
    private final DataSource dataSource;
    
    @Override
    public Health health() {
        Health.Builder status = Health.up();
        
        try {
            // Check WebSocket session manager health
            checkSessionManager(status);
            
            // Check Redis connectivity
            checkRedisHealth(status);
            
            // Check database connectivity
            checkDatabaseHealth(status);
            
            // Check recent security violations
            checkSecurityHealth(status);
            
        } catch (Exception e) {
            return Health.down()
                    .withDetail("error", e.getMessage())
                    .withDetail("timestamp", Instant.now())
                    .build();
        }
        
        return status.build();
    }
    
    private void checkSessionManager(Health.Builder status) {
        int activeSessions = sessionManager.getActiveSessionCount();
        status.withDetail("websocket.active_sessions", activeSessions);
        
        if (activeSessions > 100) {
            status.withDetail("websocket.status", "WARNING: High session count");
        }
        
        // Check for stuck sessions
        List<String> stuckSessions = sessionManager.getStuckSessions();
        if (!stuckSessions.isEmpty()) {
            status.withDetail("websocket.stuck_sessions", stuckSessions.size());
        }
    }
    
    private void checkRedisHealth(Health.Builder status) {
        try {
            String ping = redisTemplate.getConnectionFactory()
                    .getConnection()
                    .ping();
            
            status.withDetail("redis.status", "UP")
                   .withDetail("redis.ping", ping);
                   
        } catch (Exception e) {
            status.down()
                   .withDetail("redis.status", "DOWN")
                   .withDetail("redis.error", e.getMessage());
        }
    }
    
    private void checkSecurityHealth(Health.Builder status) {
        // Check recent security violations
        long recentViolations = securityService.getViolationCount(Duration.ofMinutes(5));
        
        status.withDetail("security.recent_violations", recentViolations);
        
        if (recentViolations > 10) {
            status.withDetail("security.status", "WARNING: High violation rate");
        }
    }
}
```

---

## 10. REVISED TIMELINE & IMPLEMENTATION PHASES

### 10.1 Phase-Gate Approach (8 Weeks Total)

#### Phase 1: Foundation & Security (Weeks 1-2)
**Duration:** 2 weeks  
**Focus:** Core security infrastructure and database optimization

**Week 1:**
- Enhanced WebSocket security framework implementation
- Redis cluster setup and session management
- JWT token rotation mechanism
- CSRF protection implementation
- Rate limiting service development

**Week 2:**
- Time-series database schema implementation
- Database migration scripts and testing
- Connection pooling optimization
- Security testing framework setup
- Initial performance baseline establishment

**Deliverables:**
-  Secure WebSocket handler with Redis clustering
-  Time-series database schema deployed
-  Token rotation mechanism functional
-  Security testing suite operational
-  Performance baseline documented

#### Phase 2: Core Functionality & Compliance (Weeks 3-4)
**Duration:** 2 weeks  
**Focus:** Dashboard functionality and SOX compliance

**Week 3:**
- SOX audit framework implementation
- Workflow-based configuration management
- Core dashboard service development
- Delta update system implementation
- Role-based data filtering

**Week 4:**
- React frontend with security enhancements
- WebSocket client optimization
- Comprehensive audit logging
- Configuration change approval workflow
- Integration testing

**Deliverables:**
-  SOX-compliant audit framework operational
-  Dashboard core functionality complete
-  Frontend with role-based security implemented
-  Configuration workflow system functional
-  Integration tests passing

#### Phase 3: Performance & Optimization (Weeks 5-6)
**Duration:** 2 weeks  
**Focus:** Performance optimization and scalability

**Week 5:**
- Circuit breaker implementation
- Adaptive update intervals
- Message compression and optimization
- Caching layer enhancement
- Load balancing configuration

**Week 6:**
- Performance testing and optimization
- Scalability validation (50+ concurrent users)
- Memory usage optimization
- Database query optimization
- Monitoring and alerting setup

**Deliverables:**
-  Circuit breaker patterns implemented
-  Performance targets validated (50+ users, <2s load time)
-  Monitoring and alerting operational
-  Scalability testing complete
-  Resource optimization verified

#### Phase 4: Security Validation & Production Readiness (Weeks 7-8)
**Duration:** 2 weeks  
**Focus:** Security validation, compliance testing, and production deployment

**Week 7:**
- Comprehensive security testing
- Penetration testing coordination
- SOX compliance validation
- Threat model validation
- Security audit preparation

**Week 8:**
- Production environment setup
- Deployment automation
- User acceptance testing
- Documentation finalization
- Go-live preparation and training

**Deliverables:**
-  Security testing complete with no critical issues
-  SOX compliance validated and documented
-  Production deployment successful
-  User training completed
-  Operational runbooks delivered

### 10.2 Risk Mitigation Timeline

#### Security Validation Gates
- **Week 2 End:** Initial security framework validation
- **Week 4 End:** SOX compliance framework validation
- **Week 6 End:** Performance security validation
- **Week 7 End:** Final security audit and penetration testing

#### Performance Validation Gates  
- **Week 2 End:** Database performance baseline
- **Week 4 End:** WebSocket performance under load
- **Week 6 End:** End-to-end performance validation
- **Week 8 End:** Production performance verification

#### Compliance Validation Gates
- **Week 3 End:** SOX audit framework functional testing
- **Week 5 End:** Configuration workflow compliance testing
- **Week 7 End:** Full SOX compliance validation
- **Week 8 End:** Compliance documentation review

---

## 11. THREAT MODEL ANALYSIS

### 11.1 Threat Identification Matrix

| Threat Category | Threat Description | Likelihood | Impact | Risk Score | Mitigation Implemented |
|----------------|-------------------|------------|--------|------------|----------------------|
| **Authentication** | Token theft/replay attacks | Medium | Critical | 8 |  JWT rotation, Redis validation |
| **Authorization** | Privilege escalation | Low | Critical | 6 |  Role-based filtering, audit logging |
| **Session Management** | Session hijacking | Medium | High | 7 |  Redis clustering, session validation |
| **Input Validation** | WebSocket message injection | Medium | Medium | 5 |  Input sanitization, message validation |
| **Data Exposure** | Sensitive data leakage | Low | Critical | 6 |  Field-level encryption, role filtering |
| **DoS Attacks** | Connection flooding | High | Medium | 6 |  Rate limiting, connection limits |
| **CSRF** | Cross-site request forgery | Medium | Medium | 4 |  CSRF tokens, origin validation |
| **XSS** | Cross-site scripting | Low | Medium | 3 |  Output sanitization, CSP headers |

### 11.2 Security Controls Implementation

#### Defense in Depth Strategy
```java
@Configuration
@EnableWebSecurity
public class ComprehensiveSecurityConfig {
    
    @Bean
    public SecurityFilterChain filterChain(HttpSecurity http) throws Exception {
        return http
            .sessionManagement(session -> session
                .sessionCreationPolicy(SessionCreationPolicy.STATELESS)
                .maximumSessions(1)
                .sessionRegistry(sessionRegistry()))
            
            .csrf(csrf -> csrf
                .csrfTokenRepository(csrfTokenRepository())
                .ignoringRequestMatchers("/ws/**") // Handled separately for WebSocket
                .csrfTokenRequestHandler(csrfTokenRequestHandler()))
            
            .headers(headers -> headers
                .contentSecurityPolicy("default-src 'self'; script-src 'self' 'unsafe-inline'; style-src 'self' 'unsafe-inline'")
                .frameOptions(HeadersConfigurer.FrameOptionsConfig::deny)
                .httpStrictTransportSecurity(hstsConfig -> hstsConfig
                    .maxAgeInSeconds(31536000)
                    .includeSubdomains(true)))
            
            .oauth2ResourceServer(oauth2 -> oauth2
                .jwt(jwt -> jwt
                    .jwtAuthenticationConverter(jwtAuthenticationConverter())
                    .jwtDecoder(jwtDecoder())))
            
            .authorizeHttpRequests(authz -> authz
                .requestMatchers("/actuator/health").permitAll()
                .requestMatchers("/ws/**").hasAnyRole("OPERATIONS_MANAGER", "OPERATIONS_VIEWER")
                .requestMatchers("/api/v1/monitoring/**").hasRole("OPERATIONS_MANAGER")
                .anyRequest().authenticated())
            
            .build();
    }
}
```

---

## 12. SUCCESS CRITERIA & ACCEPTANCE

### 12.1 Functional Acceptance Criteria

#### Core Functionality
-  **Real-time Updates**: Dashboard refreshes job status within 5 seconds of database changes
-  **Concurrent Users**: Supports 50+ simultaneous users without performance degradation  
-  **Mobile Responsive**: Dashboard functions correctly on tablets and mobile devices
-  **Role-based Access**: Different data visibility based on user roles (Operations Manager vs Viewer)
-  **High Availability**: 99.9% uptime with automatic failover capabilities

#### Performance Criteria
-  **Load Time**: Initial dashboard load completes within 2 seconds
-  **Update Latency**: Real-time updates delivered within 5 seconds of data changes
-  **Memory Usage**: Application memory consumption under 1GB under normal load
-  **Database Performance**: Query response times under 500ms for dashboard data

### 12.2 Security & Compliance Acceptance

#### Security Requirements
-  **Authentication**: Multi-factor JWT authentication with automatic token rotation
-  **Session Security**: Secure session management with Redis clustering and validation
-  **Input Validation**: All WebSocket messages validated and sanitized
-  **Rate Limiting**: Protection against DoS attacks with configurable thresholds
-  **Audit Logging**: Comprehensive security event logging with tamper detection

#### SOX Compliance Requirements
-  **Audit Trail**: Complete audit trail for all dashboard interactions and configuration changes
-  **Segregation of Duties**: Configuration changes require approval from different user than requester
-  **Change Control**: Workflow-based approval process for monitoring configuration modifications
-  **Data Integrity**: Tamper-evident logging with digital signatures for compliance records
-  **Access Control**: Role-based access with proper authorization controls

### 12.3 Technical Quality Gates

#### Code Quality Standards
-  **Test Coverage**: Minimum 85% code coverage with comprehensive unit and integration tests
-  **Security Testing**: No critical or high-severity security vulnerabilities
-  **Performance Testing**: Load testing validates concurrent user and response time requirements
-  **Code Review**: All code reviewed by senior developers and security team
-  **Documentation**: Complete technical documentation including API specs and operational runbooks

#### Operational Readiness
-  **Monitoring**: Comprehensive application and infrastructure monitoring in place
-  **Alerting**: Automated alerting for system health, performance, and security issues
-  **Backup/Recovery**: Disaster recovery procedures tested and documented
-  **Scaling**: Auto-scaling configuration validated under load conditions
-  **Support**: Operational runbooks and support procedures documented

---

## 13. CONCLUSION

### 13.1 Implementation Readiness Summary

This revised implementation plan comprehensively addresses all CRITICAL requirements identified in the architecture review:

** CRITICAL Requirements Addressed:**
1. **Enhanced WebSocket Security** - Redis-based session clustering, token rotation, CSRF protection, and rate limiting
2. **Database Architecture Optimization** - Time-series partitioned tables with proper indexing and caching
3. **SOX Compliance Implementation** - Comprehensive audit logging and workflow-based change control
4. **Extended Timeline** - Realistic 8-week timeline with proper security and compliance validation phases

** HIGH Priority Requirements Addressed:**
1. **Performance Optimization** - Delta updates, adaptive intervals, and circuit breaker patterns
2. **Enhanced Security Measures** - Input validation, role-based filtering, and comprehensive threat mitigation

### 13.2 Business Value Delivery

Upon successful implementation, this solution will deliver:

- **Operational Excellence**: Real-time visibility into batch job performance with proactive issue identification
- **Compliance Assurance**: SOX-compliant monitoring with comprehensive audit trails and change control
- **Security Leadership**: Enterprise-grade security controls exceeding banking industry standards
- **Scalable Architecture**: Foundation for future monitoring capabilities supporting business growth
- **Risk Mitigation**: Comprehensive threat mitigation reducing operational and compliance risks

### 13.3 Ready for Architecture Re-Review

**Implementation Plan Status: READY FOR RE-REVIEW**

This revised implementation plan addresses all critical architecture review requirements and implements banking-grade security, compliance, and performance standards. The plan is ready for final approval from the Principal Enterprise Architect and Lending Product Owner.

**Next Steps:**
1. **Architecture Re-Review** - Submit for Principal Enterprise Architect approval
2. **Product Owner Approval** - Obtain implementation approval from Lending Product Owner  
3. **Implementation Kickoff** - Begin Phase 1 upon receiving "APPROVED FOR IMPLEMENTATION" confirmation

---

**Document Status: REVISION COMPLETE - READY FOR RE-REVIEW**

**Implementation Authorization Required: PENDING ARCHITECT AND PRODUCT OWNER APPROVAL**

---

*This document is classified as INTERNAL - BANKING CONFIDENTIAL and contains proprietary information of Truist Financial Corporation. Distribution is restricted to authorized personnel only.*

*Prepared by: Senior Full Stack Developer - 2025-08-08*
*Ready for Architecture Re-Review and Implementation Approval*